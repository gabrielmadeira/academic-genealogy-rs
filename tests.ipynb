{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import sparse as sp\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "import time\n",
    "from sys import getsizeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.validation import check_array, check_X_y, check_is_fitted\n",
    "from sklearn.utils.sparsefuncs import csc_median_axis_0\n",
    "from sklearn.utils.multiclass import check_classification_targets\n",
    "\n",
    "# This is a modified version of NearestCentroid from sklearn lib\n",
    "class NearestCentroid(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, metric='euclidean', shrink_threshold=None):\n",
    "        self.metric = metric\n",
    "        self.shrink_threshold = shrink_threshold\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        if self.metric == 'precomputed':\n",
    "            raise ValueError(\"Precomputed is not supported.\")\n",
    "        # If X is sparse and the metric is \"manhattan\", store it in a csc\n",
    "        # format is easier to calculate the median.\n",
    "        if self.metric == 'manhattan':\n",
    "            X, y = check_X_y(X, y, ['csc'])\n",
    "        else:\n",
    "            X, y = check_X_y(X, y, ['csr', 'csc'])\n",
    "        is_X_sparse = sp.issparse(X)\n",
    "        if is_X_sparse and self.shrink_threshold:\n",
    "            raise ValueError(\"threshold shrinking not supported\"\n",
    "                             \" for sparse input\")\n",
    "        check_classification_targets(y)\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "        le = LabelEncoder()\n",
    "        y_ind = le.fit_transform(y)\n",
    "        self.classes_ = classes = le.classes_\n",
    "        n_classes = classes.size\n",
    "        if n_classes < 2:\n",
    "            raise ValueError('The number of classes has to be greater than'\n",
    "                             ' one; got %d class' % (n_classes))\n",
    "\n",
    "        # Mask mapping each class to its members.\n",
    "        self.centroids_ = sp.lil_matrix((n_classes, n_features), dtype=np.float64)\n",
    "        # Number of clusters in each class.\n",
    "        nk = np.zeros(n_classes)\n",
    "\n",
    "        for cur_class in range(n_classes):\n",
    "            center_mask = y_ind == cur_class\n",
    "            nk[cur_class] = np.sum(center_mask)\n",
    "            if is_X_sparse:\n",
    "                center_mask = np.where(center_mask)[0]\n",
    "\n",
    "            # XXX: Update other averaging methods according to the metrics.\n",
    "            if self.metric == \"manhattan\":\n",
    "                # NumPy does not calculate median of sparse matrices.\n",
    "                if not is_X_sparse:\n",
    "                    self.centroids_[cur_class] = np.median(X[center_mask], axis=0)\n",
    "                else:\n",
    "                    self.centroids_[cur_class] = csc_median_axis_0(X[center_mask])\n",
    "            else:\n",
    "                if self.metric != 'euclidean':\n",
    "                    warnings.warn(\"Averaging for metrics other than \"\n",
    "                                  \"euclidean and manhattan not supported. \"\n",
    "                                  \"The average is set to be the mean.\"\n",
    "                                  )\n",
    "                self.centroids_[cur_class] = X[center_mask].mean(axis=0)\n",
    "\n",
    "        if self.shrink_threshold:\n",
    "            dataset_centroid_ = np.mean(X, axis=0)\n",
    "\n",
    "            # m parameter for determining deviation\n",
    "            m = np.sqrt((1. / nk) - (1. / n_samples))\n",
    "            # Calculate deviation using the standard deviation of centroids.\n",
    "            variance = (X - self.centroids_[y_ind]) ** 2\n",
    "            variance = variance.sum(axis=0)\n",
    "            s = np.sqrt(variance / (n_samples - n_classes))\n",
    "            s += np.median(s)  # To deter outliers from affecting the results.\n",
    "            mm = m.reshape(len(m), 1)  # Reshape to allow broadcasting.\n",
    "            ms = mm * s\n",
    "            deviation = ((self.centroids_ - dataset_centroid_) / ms)\n",
    "            # Soft thresholding: if the deviation crosses 0 during shrinking,\n",
    "            # it becomes zero.\n",
    "            signs = np.sign(deviation)\n",
    "            deviation = (np.abs(deviation) - self.shrink_threshold)\n",
    "            np.clip(deviation, 0, None, out=deviation)\n",
    "            deviation *= signs\n",
    "            # Now adjust the centroids using the deviation\n",
    "            msd = ms * deviation\n",
    "            self.centroids_ = dataset_centroid_[np.newaxis, :] + msd\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        check_is_fitted(self, 'centroids_')\n",
    "\n",
    "        X = check_array(X, accept_sparse='csr')\n",
    "        \n",
    "        return np.argsort(pairwise_distances(X, self.centroids_, metric=self.metric))[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_doc_vect_representation = pickle.load(open('y_doc_vect_representation', 'rb'))\n",
    "X_doc_vect_representation = pickle.load(open('X_doc_vect_representation', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# print(y_doc_vect_representation[1][1])\n",
    "\n",
    "clf = NearestCentroid()\n",
    "clf.fit(X_doc_vect_representation, y_doc_vect_representation[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open(\"clf_all_data1\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load(open('vectorizer', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking fold 1 document 0:\n",
      "0: 551350\n",
      "1: 570726\n",
      "2: 538029\n",
      "3: 559202\n",
      "15829: 546437 <---\n",
      "65633: 582037 <---\n",
      "Ranking fold 2 document 0:\n",
      "0: 551350\n",
      "1: 516697\n",
      "2: 570726\n",
      "3: 538029\n",
      "15876: 546437 <---\n",
      "65813: 582037 <---\n",
      "Ranking fold 3 document 0:\n",
      "0: 516697\n",
      "1: 570726\n",
      "2: 551350\n",
      "3: 540612\n",
      "15882: 546437 <---\n",
      "65641: 582037 <---\n",
      "Ranking fold 4 document 0:\n",
      "0: 570726\n",
      "1: 516697\n",
      "2: 551350\n",
      "3: 538029\n",
      "15852: 546437 <---\n",
      "65077: 582037 <---\n",
      "Ranking fold 5 document 0:\n",
      "0: 551350\n",
      "1: 516697\n",
      "2: 538029\n",
      "3: 540612\n",
      "15852: 546437 <---\n",
      "66405: 582037 <---\n",
      "Ranking fold 6 document 0:\n",
      "0: 570726\n",
      "1: 516697\n",
      "2: 551350\n",
      "3: 538029\n",
      "15891: 546437 <---\n",
      "64857: 582037 <---\n",
      "Ranking fold 7 document 0:\n",
      "0: 551350\n",
      "1: 516697\n",
      "2: 570726\n",
      "3: 538029\n",
      "15874: 546437 <---\n",
      "69387: 582037 <---\n",
      "Ranking fold 8 document 0:\n",
      "0: 570726\n",
      "1: 516697\n",
      "2: 551350\n",
      "3: 578980\n",
      "24169: 546437 <---\n",
      "65516: 582037 <---\n",
      "Ranking fold 9 document 0:\n",
      "0: 570726\n",
      "1: 551350\n",
      "2: 516697\n",
      "3: 538029\n",
      "27247: 546437 <---\n",
      "65530: 582037 <---\n",
      "Ranking fold 10 document 0:\n",
      "0: 551350\n",
      "1: 516697\n",
      "2: 570726\n",
      "3: 540612\n",
      "27268: 546437 <---\n",
      "65625: 582037 <---\n",
      "Ranking fold 1 document 1:\n",
      "0: 571050 <---\n",
      "1: 568493\n",
      "2: 572094\n",
      "3: 555054\n",
      "Ranking fold 2 document 1:\n",
      "0: 571050 <---\n",
      "1: 568493\n",
      "2: 555054\n",
      "3: 568785\n",
      "Ranking fold 3 document 1:\n",
      "0: 571050 <---\n",
      "1: 555054\n",
      "2: 556151\n",
      "3: 568493\n",
      "Ranking fold 4 document 1:\n",
      "0: 571050 <---\n",
      "1: 568493\n",
      "2: 573110\n",
      "3: 505369\n",
      "Ranking fold 5 document 1:\n",
      "0: 571050 <---\n",
      "1: 568493\n",
      "2: 573110\n",
      "3: 556151\n",
      "Ranking fold 6 document 1:\n",
      "0: 571050 <---\n",
      "1: 568493\n",
      "2: 573110\n",
      "3: 572094\n",
      "Ranking fold 7 document 1:\n",
      "0: 571050 <---\n",
      "1: 568493\n",
      "2: 573110\n",
      "3: 572094\n",
      "Ranking fold 8 document 1:\n",
      "0: 571050 <---\n",
      "1: 568493\n",
      "2: 572094\n",
      "3: 555054\n",
      "Ranking fold 9 document 1:\n",
      "0: 571050 <---\n",
      "1: 572094\n",
      "2: 568493\n",
      "3: 556151\n",
      "Ranking fold 10 document 1:\n",
      "0: 571050 <---\n",
      "1: 568493\n",
      "2: 572094\n",
      "3: 555054\n",
      "Ranking fold 1 document 2:\n",
      "0: 532526\n",
      "1: 531510\n",
      "2: 551935\n",
      "3: 578294\n",
      "4: 556151 <---\n",
      "59872: 574936 <---\n",
      "Ranking fold 2 document 2:\n",
      "0: 532526\n",
      "1: 531510\n",
      "2: 578294\n",
      "3: 551935\n",
      "4: 556151 <---\n",
      "59690: 574936 <---\n",
      "Ranking fold 3 document 2:\n",
      "0: 532526\n",
      "1: 531510\n",
      "2: 578294\n",
      "3: 551935\n",
      "5: 556151 <---\n",
      "59324: 574936 <---\n",
      "Ranking fold 4 document 2:\n",
      "0: 532526\n",
      "1: 531510\n",
      "2: 551935\n",
      "3: 578294\n",
      "4: 556151 <---\n",
      "58606: 574936 <---\n",
      "Ranking fold 5 document 2:\n",
      "0: 532526\n",
      "1: 531510\n",
      "2: 578294\n",
      "3: 551935\n",
      "7: 556151 <---\n",
      "58281: 574936 <---\n",
      "Ranking fold 6 document 2:\n",
      "0: 532526\n",
      "1: 531510\n",
      "2: 578294\n",
      "3: 551935\n",
      "4: 556151 <---\n",
      "59037: 574936 <---\n",
      "Ranking fold 7 document 2:\n",
      "0: 532526\n",
      "1: 531510\n",
      "2: 551935\n",
      "3: 556151 <---\n",
      "59737: 574936 <---\n",
      "Ranking fold 8 document 2:\n",
      "0: 532526\n",
      "1: 531510\n",
      "2: 551935\n",
      "3: 556151 <---\n",
      "58564: 574936 <---\n",
      "Ranking fold 9 document 2:\n",
      "0: 532526\n",
      "1: 531510\n",
      "2: 551935\n",
      "3: 578294\n",
      "4: 556151 <---\n",
      "58409: 574936 <---\n",
      "Ranking fold 10 document 2:\n",
      "0: 532526\n",
      "1: 531510\n",
      "2: 578294\n",
      "3: 551935\n",
      "4: 556151 <---\n",
      "58848: 574936 <---\n"
     ]
    }
   ],
   "source": [
    "title = [\"Filogenia molecular e análise morfológica de espécies de Paralucilia Brauer & Bergenstamm, 1891 (Insecta, Diptera, Calliphoridae)\",\n",
    "        \"Um método para deduplicação de metadados bibliográficos baseado no empilhamento de classificadores\",\n",
    "        \"Modelo RHA - Retroalimentação em Hipermídia Adaptativa\"]\n",
    "abstract = [\"Paralucilia Brauer & Bergenstamm, 1891 (Insecta, Diptera, Calliphoridae) é um gênero que compreende espécies Neotropicais comumente observadas associadas a cadáveres e carcaças em ambientes sem, ou com pouca perturbação antrópica. Divergências na literatura quanto ao número e nomenclatura das espécies válidas levam à falta de consenso na denominação das espécies em estudos que levantam informações sobre a biodiversidade e os de importância forense. Neste estudo foi proposta a primeira hipótese filogenética baseada em dados moleculares (dos genes COI, ITS2, 16S e 28S) para diferentes morfotipos de Paralucilia [P. fulvinota, P. pseudolyrcea, P. paraensis, Paralucilia sp.1 (=P. nigrofacialis), Paralucilia sp.2 e Paralucilia sp.3 (=P. xanthogeneiates)], visando resolver os conflitos taxonômicos do gênero. Análises de Máxima Parcimônia, Máxima Verossimilhança e Inferência Bayesiana recuperaram o grupo como sendo monofilético, tal como tem sido observado para os demais gêneros de Chrysomyinae Neotropicais. Após todas as análises concluídas destacamos que devem ser consideradas como espécies válidas para o gênero: P. fulvinota, P. pseudolyrcea e P. paraensis. Propomos a sinonimização de Paralucilia nigrofacialis para P. fulvinota, uma vez que se refere a uma variação morfológica polimórfica desta espécie; e a sinonimização de P. xanthogeneiates para P. pseudolyrcea. O status de P. borgmeieri deve ser mantido como incerto até que estudos mais aprofundados possam ser conduzidos, além da necessidade de designação de um lectótipo. A partir das análises morfológicas foram considerados os seguintes caracteres como sendo de valor diagnóstico para as espécies de Paralucilia: cor da microtricosidade da pós-gena; cor dos cílios da pós-gena; número de faixas longitudinais no tórax; cor do espiráculo anterior; e número de cerdas posterodorsais da tíbia posterior. Além disso, o polimorfismo de P. fulvinota foi descrito mais aprofundadamente visando evitar o surgimento de novos conflitos taxonômicos. Este estudo contribuiu para o esclarecimento da taxonomia de Paralucilia, e as informações aqui levantadas vêm a ser úteis a fim de minimizar o impedimento taxonômico entre os dípteros Neotropicais.\",\n",
    "            \"Metadados bibliográficos duplicados são registros que correspondem a referências bibliográficas semanticamente equivalentes, ou seja, que descrevem a mesma publicação. Identificar metadados bibliográficos duplicados em uma ou mais bibliotecas digitais é uma tarefa essencial para garantir a qualidade de alguns serviços como busca, navegação e recomendação de conteúdo. Embora diversos padrões de metadados tenham sido propostos, eles não resolvem totalmente os problemas de interoperabilidade porque mesmo que exista um mapeamento entre diferentes esquemas de metadados, podem existir variações na representação do conteúdo. Grande parte dos trabalhos propostos para identificar duplicatas aplica uma ou mais funções sobre o conteúdo de determinados campos no intuito de captar a similaridade entre os registros. Entretanto, é necessário escolher um limiar que defina se dois registros são suficientemente similares para serem considerados semanticamente equivalentes ou duplicados. Trabalhos mais recentes tratam a deduplicação de registros como um problema de classificação de dados, em que um modelo preditivo é treinado para estimar a que objeto do mundo real um registro faz referência. O objetivo principal desta tese é o desenvolvimento de um método efetivo e automático para identificar metadados bibliográficos duplicados, combinando o aprendizado de múltiplos classificadores supervisionados, sem a necessidade de intervenção humana na definição de limiares de similaridade. Sobre o conjunto de treinamento são aplicadas funções de similaridade desenvolvidas especificamente para o contexto de bibliotecas digitais e com baixo custo computacional. Os escores produzidos pelas funções são utilizados para treinar múltiplos modelos de classificação heterogêneos, ou seja, a partir de algoritmos de diversos tipos: baseados em árvores, regras, redes neurais artificiais e probabilísticos. Os classificadores aprendidos são combinados através da estratégia de empilhamento visando potencializar o resultado da deduplicação a partir do conhecimento heterogêneo adquirido individualmente pelos algoritmo de aprendizagem. O modelo de classificação final é aplicado aos pares candidatos ao casamento retornados por uma estratégia de blocagem de dois níveis bastante eficiente. A solução proposta é baseada na hipótese de que o empilhamento de classificadores supervisionados pode aumentar a qualidade da deduplicação quando comparado a outras estratégias de combinação. A avaliação experimental mostra que a hipótese foi confirmada quando o método proposto é comparado com a escolha do melhor classificador e com o voto da maioria. Ainda são analisados o impacto da diversidade dos classificadores no resultado do empilhamento e os casos de falha do método proposto.\",\n",
    "            \"A presente pesquisa tem como objetivo propor uma extensão para modelos de referência em hipermídia adaptativa de acordo com resultados de avaliação de aprendizagem e estilos cognitivos dos aprendizes. É proposto, portanto, um modelo denominado RHA, Modelo de Retroalimentação em Hipermídia Adaptativa, que utiliza os resultados obtidos com as avaliações de aprendizagem e as definições derivadas dos estilos cognitivos dos aprendizes a fim de prover a retroalimentação dos demais modelos existentes em um hipermídia adaptativo. Na concepção do RHA foi adotada a representação por meio da UML (Unified Modeling Language) com objetivo de diminuir o risco de ambigüidade, facilitar o processo de modelagem computacional, proporcionar o reaproveitamento do modelo e otimizar a implementação do mesmo. Para apoiar a criação do RHA, foi adotado o modelo de referência Munich. Este utiliza UML e apresenta uma arquitetura que contempla módulos tradicionais dos hipermídias adaptativos, tais como: modelo de domínio, de usuário e de adaptatividade; porém, como os demais modelos de referência atuais, este não contempla a definição de itens explícitos à reutilização dos dados obtidos com as avaliações de aprendizagem. O modelo RHA foi criado como uma extensão do Munich, com concepção fundamentada em duas dimensões de estilos cognitivos estabelecidos (MESSICK, 1976), que nortearam a escolha de instrumentos de avaliação de aprendizagem destinados à modalidade ensino a distância. Os instrumentos de avaliação de aprendizagem abrangem atividades definidas de acordo com um grupo de ferramentas de comunicação e interação (síncronas e assíncronas) amplamente adotadas no ensino a distância. A modelagem do RHA envolve aspectos relativos a UML, como a criação das classes com seus atributos e métodos e os relacionamentos entre as classes já existentes no Munich. Para simular a aplicação do modelo RHA, foi definido um domínio de conhecimento relacionado à área de apoio ao ensino sobre Mercado de Capitais. Este tema se mostrou adequado, pois dada à quantidade de materiais e informações disponíveis sobre o assunto, é relevante a adoção de diferentes estilos de aprendizagem com tipos particulares de conteúdos e empregos das ferramentas de comunicação e interação, visando à avaliação de aprendizagem, para públicos distintos. Atualmente o número de cursos a distância no referido domínio de conhecimento é escasso, o que o torna ainda mais relevante para exploração.\"]\n",
    "y = [[546437, 582037],[571050],[574936,556151]]\n",
    "\n",
    "for iii in range(0,3):\n",
    "    X_test = vectorizer.transform([title[iii] + \" \" + abstract[iii]])\n",
    "    y_test = y[iii]\n",
    "    for ii in range(1,11):\n",
    "        clf = pickle.load(open('clfs/fold'+str(ii)+'_clf', 'rb'))\n",
    "        out = clf.predict(X_test)\n",
    "        print('Ranking fold '+str(ii)+' document '+str(iii)+':')\n",
    "        for i in range(0,70000):\n",
    "            if clf.classes_[out[0][i]] in y_test:\n",
    "                print(str(i)+': '+str(clf.classes_[out[0][i]])+' <---')\n",
    "            elif i in [0,1,2,3]:\n",
    "                print(str(i)+': '+str(clf.classes_[out[0][i]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
