{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.io.sql as sqlio\n",
    "import psycopg2\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import sparse as sp\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "conn = psycopg2.connect(host=\"localhost\", port=5432, dbname=\"thegoldtree\", user=\"postgres\", password=\"postgres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = None\n",
    "sql = \"select title, abstract, id_advisor, id, id_author from relationship;\"\n",
    "docs = sqlio.read_sql_query(sql, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs['title'] = docs['title'].apply(lambda x: x if isinstance(x, str) else '')\n",
    "docs['abstract'] = docs['abstract'].apply(lambda x: x if isinstance(x, str) else '')\n",
    "# docs['title_abstract'] = docs['title'] + ' ' + docs['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=False, norm='l1', stop_words=stopwords.words('portuguese'))\n",
    "response = vectorizer.fit_transform(docs['title'] + ' ' + docs['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select * from researcher;\"\n",
    "researcher = sqlio.read_sql_query(sql, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_doc_vect_representation = None\n",
    "y_doc_vect_representation = [None,[None] * 800000]\n",
    "\n",
    "aux_count = 0\n",
    "\n",
    "for index, row in researcher.iterrows(): \n",
    "    \n",
    "    researcher_all_advisors = docs[docs.id_author == row['id']].id_advisor.values\n",
    "    for i in docs[docs.id_author == row['id']].index:\n",
    "        researcher_advisor       = docs[docs.index == i].id_advisor.values[0]\n",
    "        if X_doc_vect_representation == None:\n",
    "            X_doc_vect_representation = response[i]\n",
    "            y_doc_vect_representation[0] = np.array([researcher_advisor])\n",
    "            y_doc_vect_representation[1][aux_count] = np.unique(researcher_all_advisors)\n",
    "        else:\n",
    "            X_doc_vect_representation = sp.vstack((X_doc_vect_representation,response[i]))\n",
    "            y_doc_vect_representation[0] = np.append(y_doc_vect_representation[0], researcher_advisor)\n",
    "            y_doc_vect_representation[1][aux_count] = np.unique(researcher_all_advisors)\n",
    "        \n",
    "        aux_count += 1\n",
    "        \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(X_doc_vect_representation, open(\"X_doc_vect_representation\", \"wb\"))\n",
    "pickle.dump(y_doc_vect_representation, open(\"y_doc_vect_representation\", \"wb\"))\n",
    "pickle.dump(vectorizer, open(\"vectorizer\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, random_state=245, shuffle=True)\n",
    "kf.get_n_splits(X_doc_vect_representation)\n",
    "\n",
    "aux_count = 1\n",
    "\n",
    "y_doc_vect_representation[1] = np.array(y_doc_vect_representation[1])\n",
    "\n",
    "for train_index, test_index in kf.split(X_doc_vect_representation):\n",
    "\n",
    "    train_X_doc_vect_representation, test_X_doc_vect_representation = X_doc_vect_representation[train_index], X_doc_vect_representation[test_index]\n",
    "    train_y_doc_vect_representation_0, test_y_doc_vect_representation_0 = y_doc_vect_representation[0][train_index], y_doc_vect_representation[0][test_index]\n",
    "    train_y_doc_vect_representation_1, test_y_doc_vect_representation_1 = y_doc_vect_representation[1][train_index], y_doc_vect_representation[1][test_index]\n",
    "    \n",
    "    pickle.dump(train_X_doc_vect_representation, open(\"fold\"+str(aux_count)+\"_train_X_doc_vect_representation\", \"wb\"))\n",
    "    pickle.dump(train_y_doc_vect_representation_0, open(\"fold\"+str(aux_count)+\"_train_y_doc_vect_representation\", \"wb\"))\n",
    "    \n",
    "    pickle.dump(test_X_doc_vect_representation, open(\"fold\"+str(aux_count)+\"_test_X_doc_vect_representation\", \"wb\"))\n",
    "    pickle.dump([test_y_doc_vect_representation_0,test_y_doc_vect_representation_1], open(\"fold\"+str(aux_count)+\"_test_y_doc_vect_representation\", \"wb\"))\n",
    "    \n",
    "    aux_count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
